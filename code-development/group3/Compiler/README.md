# Compiler <br>
Compiler คือโปรแกรมคอมพิวเตอร์ที่แปลงภาษาโปรแกรมระดับสูง (high-level programming language) ไปเป็นภาษาเครื่อง (machine language) ภาษาเครื่องเป็นภาษาที่ CPU ของคอมพิวเตอร์เข้าใจและใช้งานได้โดยตรง Compiler ทำหน้าที่แปลโค้ดที่เขียนโดยมนุษย์ให้เป็นชุดคำสั่งที่ CPU เข้าใจได้
## โครงสร้างการทำงาน Compiler
![How does the compiler work](https://media.geeksforgeeks.org/wp-content/uploads/20200524115722/Capture3311.png)<br>
[Lexical Analysis](#Lexical-Analysis)<br>
[Syntax Analysis](#Syntax-Analysis)<br>
[Semantic Analysis](#Semantic-Analysis)<br>
[Intermediate Code Generation](#ICG)<br>
[Machine Independent code optimizer](#MIO)<br>


## Lexical Analysis (การวิเคราะห์ตัวอักษร)
<a name="Lexical-Analysis"></a>
เป็นขั้นตอนแรกในการดำเนินการคอมไพล์โปรแกรมที่เป็นภาษามนุษย์ไปเป็นภาษาเครื่อง ซึ่งมักจะเป็นขั้นตอนที่สำคัญในกระบวนการคอมไพล์โดยทั่วไป เป้าหมายหลักของ lexical analysis คือการแยกแยะและการจับคู่ส่วนประกอบของโค้ดโปรแกรมให้อยู่ในรูปแบบที่สามารถทำการวิเคราะห์และแปลงไปเป็นโค้ดที่เป็นภาษาเครื่องได้ ซึ่งมันมุ่งเน้นไปที่การตรวจสอบความถูกต้องของโค้ดในระดับของตัวอักษรหรือ Token ซึ่งเป็นชุดของตัวอักษรที่มีความหมายรวมกันเป็นหน่วยๆ ซึ่งมักจะรวมถึงคำสั่ง เครื่องหมาย และค่าคงที่ เป็นต้น <br>
![Lexical Analysis](https://binaryterms.com/wp-content/uploads/2021/11/Lexical-Analysis-in-Compiler.jpg)<br>
<a name="Lexical-Analyser"></a>
### Lexical Analyser ทำงานยังไง
* Input preprocessing:  ขั้นตอนนี้จะทำความสะอาดข้อความอินพุตเพื่อเตรียมสำหรับการวิเคราะห์ทางไวยากรณ์ ซึ่งรวมถึงการลบส่วนประกอบที่ไม่จำเป็นออกไป เช่น คำอธิบาย ช่องว่าง ตัวอักษรพิเศษ เป็นต้น<br>
* Tokenization: ขั้นตอนนี้จะแบ่งข้อความอินพุตออกเป็นหน่วยข้อมูลเล็กๆ ที่เรียกว่า "โทเค็น" โดยมักจะใช้รูปแบบหรือการแสดงออกแบบปกติ (regular expressions) ในการจับคู่ตัวอักษรในข้อความอินพุตกับรูปแบบต่างๆ ของโทเค็น
* Token classification: ขั้นตอนนี้จะกำหนดประเภทของแต่ละโทเค็น ตัวอย่างเช่น ในภาษาโปรแกรม ตัวแบ่งประเภทโทเค็น (lexer) อาจจำแนกคีย์เวิร์ด ตัวระบุ ตัวดำเนินการ และสัญลักษณ์วรรคตอน เป็นประเภทโทเค็นที่แตกต่างกัน
* Token validation: ขั้นตอนนี้จะตรวจสอบว่าโทเค็นแต่ละโทเค็นถูกต้องตามกฎของภาษาที่ใช้เขียน ตัวอย่างเช่น ตัวแบ่งประเภทโทเค็นอาจตรวจสอบว่า ชื่อตัวแปรเป็นตัวระบุที่ถูกต้อง หรือ ตัวดำเนินการมีไวยากรณ์ที่ถูกต้อง
* Output generation: ขั้นตอนสุดท้าย ตัวแบ่งประเภทโทเค็นจะสร้างผลลัพธ์ของขั้นตอนการวิเคราะห์ทางไวยากรณ์เบื้องต้น ซึ่งโดยทั่วไปเป็นรายการของโทเค็น รายการโทเค็นนี้สามารถส่งต่อไปยังขั้นตอนถัดไปของการแปลรหัสหรือการตีความ
```
int main()
{
  // 2 variables
  int a, b;
  a = 10;
 return 0;
}
```
Lexical Analysis จะแยกโค้ด C นี้เป็นโทเค็นดังต่อไปนี้:<br>

['int'  'main'  '('  ')'  '{'  'int'  'a' ','  'b'  ';'
 'a'  '='  '10'  ';' 'return'  '0'  ';'  '}]

### ไวยากรณ์กำกวม (Ambiguous Grammar)
ลักษณะของภาษาใน lexical analysis อาจทำให้เกิดความคลุมเครือในการแยกวิเคราะห์สัญลักษณ์ (token)<br>
ตัวอย่าง<br>
<ul>
  <li>"123" : สามารถตีความได้ทั้งเลขจำนวนเต็ม (integer) หรือ เลขทศนิยม (floating-point)</li>
  <li>"++" : สามารถตีความได้ทั้ง operator เพิ่มทีละ 1 หรือ operator เพิ่มทีละ 2</li>
  <li>if" : สามารถตีความได้ทั้ง keyword ของภาษาโปรแกรม หรือ conjunctions</li>
</ul>

<a name="Syntax-Analysis"></a>
## Syntax Analysis (การวิเคราะห์ไวยากรณ์)
Syntax Analysis หรือ Parsing จะทำหน้าที่ ตรวจสอบ ว่า โครงสร้างของโค้ด นั้น ถูกต้องตามกฎไวยากรณ์ของภาษาโปรแกรม หรือไม่ โดยใช้ parse tree หรือ abstract syntax tree (AST) แสดงโครงสร้างของโค้ด
ตัวอย่าง
```
x = 10 + 5

```
Lexical Analysis: แยก "x", "=", "10", "+", "5" ออกจากกัน<br>
Syntax Analysis: วิเคราะห์ว่า "x" เป็นตัวแปร "=" เป็นตัวดำเนินการ "10" และ "5" เป็นตัวถูกดำเนินการ และเรียงลำดับถูกต้อง<br>
Parse Tree:
```

    =
  /   \
 x     +
      / \
     10  5

```
AST:
```

=
|
x
|
+
|
10
5

```
### ตัวอย่างรูปแบบ Syntax Analysis
<ul>
  <li>
     LL Parsing คือ อัลกอริทึมการแยกวิเคราะห์แบบ Top-down ที่ใช้ในการวิเคราะห์ไวยากรณ์ของภาษาโปรแกรม เริ่มต้นจากโหนดรากของต้นไม้การแยกวิเคราะห์ (parse tree) และสร้างต้นไม้โดยขยายตัวที่ไม่ใช่ปลายทาง (non-terminals) ลงมาทีละขั้นตอน
  </li>
  <li>
    LL Parsing คือ อัลกอริทึมการแยกวิเคราะห์แบบ Top-down ที่ใช้ในการวิเคราะห์ไวยากรณ์ของภาษาโปรแกรม เริ่มต้นจากโหนดรากของต้นไม้การแยกวิเคราะห์ (parse tree) และสร้างต้นไม้โดยขยายตัวที่ไม่ใช่ปลายทาง (non-terminals) ลงมาทีละขั้นตอน
  </li>
  <li>
    LR(1) parsing เป็นรูปแบบหนึ่งของ LR parsing ที่ใช้ สัญลักษณ์ Lookahead ในการแก้ความคลุมเครือของกฎไวยากรณ์ ช่วยให้การแยกวิเคราะห์มีความแม่นยำและชัดเจนมากขึ้น
  </li>
  <li>>
    LALR parsing เป็นรูปแบบหนึ่งของ LR parsing ที่พัฒนาต่อยอดจาก LR(1) parsing มุ่งเน้นไปที่การลดขนาดและความซับซ้อนของตาราง parsing โดยใช้ชุดสัญลักษณ์ Lookahead ที่จำกัดลง
  </li>
</ul>

<a name="Semantic-Analysis"></a>
## Semantic Analysis (การวิเคราะห์เชิงความหมาย)
ขั้นตอนที่ดำเนินต่อจาก Syntax Analysis หลังจากที่ตรวจสอบความถูกต้องตามไวยากรณ์ของภาษาโปรแกรมแล้ว เป้าหมายหลักของ Semantic Analysis คือการวิเคราะห์ความหมายเชิงตรรกะของโค้ด โดยมีหน้าที่สำคัญดังนี้:
* ตรวจสอบความถูกต้องและสอดคล้องของชนิดข้อมูล: เช่น ตรวจสอบว่าการบวกตัวเลขกับสตริงนั้นไม่ถูกต้อง, การเรียกใช้ฟังก์ชันกับอาร์กิวเมนต์ที่ไม่ตรงตามชนิดข้อมูลที่กำหนดไว้
* สร้างตารางสัญลักษณ์ (Symbol Table): เก็บข้อมูลเกี่ยวกับตัวแปร ฟังก์ชัน และชนิดข้อมูลต่างๆ ที่ใช้ในโค้ด
* วิเคราะห์การไหลของข้อมูล (Data Flow Analysis): วิเคราะห์ว่าข้อมูลไหลผ่านโค้ดอย่างไร ช่วยให้ Compiler
* เพิ่มประสิทธิภาพโค้ด (Code Optimization): วิเคราะห์โค้ดเพื่อหาโอกาสในการเพิ่มประสิทธิภาพ เช่น
```
public class Factorial {

    public static int factorial(int n) {
        if (n < 0) {
            throw new IllegalArgumentException("n must be non-negative!");
        } else if (n == 0) {
            return 1;
        } else {
            return n * factorial(n - 1);
        }
    }

    public static void main(String[] args) {
        int n = 5;
        int result = factorial(n);
        System.out.println(n + "! = " + result);
    }
}
```
ในการวิเคราะห์ Semantic Analysis ของฟังก์ชัน Factorial ในตัวอย่างโค้ด Java นี้ Java Compiler จะมองดังนี้:<br>
*** ตัวอย่าง ***
* Type Checking Compiler จะตรวจสอบว่าชนิดข้อมูลของตัวแปร(variable)และนิพจน์(expression)สอดคล้องกันหรือไม่
    - n ถูกประกาศเป็น int และใช้กับการเปรียบเทียบ (< 0) และการคำนวณทางคณิตศาสตร์ (+, *)
    - ผลลัพธ์ของ factorial เป็น int
    - การบวกและการคูณใช้กับ int เท่านั้น
  Compiler พบว่าชนิดข้อมูลถูกต้องตามกฎภาษา Java
* Validity Checking:
        - Compiler จะตรวจสอบว่าการดำเนินการต่างๆถูกต้องตามตรรกะหรือไม่
        - ตรวจสอบเงื่อนไข n < 0 กรณีอินพุตเป็นค่าลบ
        - ตรวจสอบการส่งและรับค่าของฟังก์ชัน factorial
  Compiler พบว่าโค้ดถูกต้องตามตรรกะ

<a name="ICG"></a>
## Intermediate Code Generation (ICG)
เป็นขั้นตอนหนึ่งในกระบวนการของ Compiler ที่อยู่ระหว่างขั้นตอน Syntax Analysis และ Code Generation โดยมีหน้าที่ในการแปลงโค้ดต้นฉบา (source code) ไปเป็นรูปแบบกลางที่ง่ายต่อการวิเคราะห์และเพิ่มประสิทธิภาพก่อนที่จะแปลเป็นภาษาเครื่อง
ประโยชน์ของ ICG:<br>
* เพิ่มความอิสระจากภาษาเป้าหมาย: ICG ไม่ขึ้นอยู่กับภาษาเป้าหมายที่ต้องการแปล ทำให้ Compiler สามารถรองรับการแปลไปยังหลายภาษาเป้าหมาย
* ง่ายต่อการวิเคราะห์และเพิ่มประสิทธิภาพ: โครงสร้างของ ICG เรียบง่ายกว่าโค้ดต้นฉบา ทำให้เครื่องมือวิเคราะห์และเพิ่มประสิทธิภาพทำงานได้ง่ายขึ้น
* สะดวกในการดีบัก: การดีบักโค้ด ICG ทำได้ง่ายกว่าการดีบักโค้ดต้นฉบา

ลักษณะของ ICG:<br>
* ICG เป็นรูปแบบการแทนคำสั่งและข้อมูลในภาษาที่เป็นกลาง ไม่ขึ้นอยู่กับภาษาโปรแกรมใดๆ
* ICG ประกอบด้วยคำสั่งพื้นฐาน เช่น การบวก การลบ การเปรียบเทียบ การกระโดด และการเรียกฟังก์ชัน
* ICG อาจจะมีการใช้ตารางสัญลักษณ์ (Symbol table) เพื่อเก็บข้อมูลเกี่ยวกับตัวแปร ฟังก์ชัน และชนิดข้อมูล

ขั้นตอนหลักของ ICG:<br>
* สร้าง Abstract Syntax Tree (AST): Syntax Analysis สร้างโครงสร้างข้อมูลที่แสดงโครงสร้างของโค้ดต้นฉบา
* เดินผ่าน AST และสร้าง ICG: เดินผ่าน AST และแปลงแต่ละโหนดเป็นคำสั่ง ICG
* เพิ่มประสิทธิภาพ ICG (Optional): ใช้เทคนิคต่างๆ เพื่อเพิ่มประสิทธิภาพ ICG
* แปลง ICG เป็นภาษาเป้าหมาย: Code Generation แปลง ICG เป็นภาษาเป้าหมาย เช่น ภาษาเครื่อง

<a name="MIO"></a>
## Machine Independent code optimizer
Machine Independent code optimizer (MIO) หรือที่เรียกอีกอย่างว่า Global optimizer เป็นเครื่องมือที่ใช้ในการเพิ่มประสิทธิภาพโค้ด โดยไม่ขึ้นอยู่กับสถาปัตยกรรมของเครื่องคอมพิวเตอร์ (Machine-independent) ทำงานในขั้นตอนของ Intermediate Code Generation (ICG) ของกระบวนการทำงานของ Compiler
หน้าที่หลักของ MIO:<br>
* วิเคราะห์และปรับแต่งโครงสร้างของโค้ด:
        - เช่น การค้นหาและกำจัด redundant code (โค้ดที่ทำสิ่งเดียวกันซ้ำ)
        - การเปลี่ยนแปลงลำดับการดำเนินการ (Instruction scheduling)
        - การกำหนดตัวแปรร่วม (Common subexpression elimination)
* เพิ่มประสิทธิภาพการจัดการหน่วยความจำ:
        - เช่น การวิเคราะห์การใช้หน่วยความจำและกำหนดอายุการใช้งานของตัวแปร (Dataflow analysis)
        - การจัดสรรพหน่วยความจำอย่างเหมาะสม (Memory allocation)
* เพิ่มประสิทธิภาพการคำนวณ:
        - เช่น การใช้เทคนิคการคำนวณทางลัด (Strength reduction)
        - การแปลงการคำนวณเป็นคำสั่งที่เหมาะสมกับสถาปัตยกรรมของเครื่อง (Loop unrolling)

# References
[การออกแบบ Compiler](https://www.geeksforgeeks.org/introduction-of-compiler-design/?ref=lbp)<br>
[การทำงานJVM](https://docs.oracle.com/en/java/java-components/index.html)<br>
[รายละเอียด GCC](https://gcc.gnu.org/)<br>
[]()<br>
[]()<br>
[]()<br>
